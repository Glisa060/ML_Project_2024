{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T14:35:16.704916Z",
     "iopub.status.busy": "2024-01-13T14:35:16.702909Z",
     "iopub.status.idle": "2024-01-13T14:35:16.729192Z",
     "shell.execute_reply": "2024-01-13T14:35:16.728188Z",
     "shell.execute_reply.started": "2024-01-13T14:35:16.704916Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x1c3cc5f7550>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T14:35:18.929410Z",
     "iopub.status.busy": "2024-01-13T14:35:18.928409Z",
     "iopub.status.idle": "2024-01-13T14:35:18.937067Z",
     "shell.execute_reply": "2024-01-13T14:35:18.935061Z",
     "shell.execute_reply.started": "2024-01-13T14:35:18.929410Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH = \"plant-seedlings-classification/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T14:35:21.172962Z",
     "iopub.status.busy": "2024-01-13T14:35:21.171998Z",
     "iopub.status.idle": "2024-01-13T14:35:21.194977Z",
     "shell.execute_reply": "2024-01-13T14:35:21.192971Z",
     "shell.execute_reply.started": "2024-01-13T14:35:21.172962Z"
    }
   },
   "outputs": [],
   "source": [
    "# loadingg test set data:\n",
    "def load_test_data(data_path, transform):\n",
    "    temp = []\n",
    "\n",
    "    allTestImages = os.listdir(data_path)\n",
    "    for x in allTestImages:\n",
    "        img = Image.open(data_path + \"/\" + allTestImages[1])\n",
    "        temp.append(transform(np.array(img)))\n",
    "\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T14:35:22.518992Z",
     "iopub.status.busy": "2024-01-13T14:35:22.516993Z",
     "iopub.status.idle": "2024-01-13T14:35:22.534729Z",
     "shell.execute_reply": "2024-01-13T14:35:22.529719Z",
     "shell.execute_reply.started": "2024-01-13T14:35:22.518992Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_img(img):\n",
    "    return img / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T14:35:24.256864Z",
     "iopub.status.busy": "2024-01-13T14:35:24.255869Z",
     "iopub.status.idle": "2024-01-13T14:35:24.628244Z",
     "shell.execute_reply": "2024-01-13T14:35:24.627131Z",
     "shell.execute_reply.started": "2024-01-13T14:35:24.256864Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading train dataset\n",
    "transform = {\n",
    "    \"train\": transforms.Compose(\n",
    "        [\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: normalize_img(x)),\n",
    "        ]\n",
    "    ),\n",
    "    \"test\": transforms.Compose(\n",
    "        [\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: normalize_img(x)),\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "trainData = torchvision.datasets.ImageFolder(\n",
    "    root=PATH + \"train\", transform=transform[\"train\"]\n",
    ")\n",
    "trainLen = len(trainData)\n",
    "trainData1, valData = torch.utils.data.dataset.random_split(\n",
    "    trainData, [int((trainLen * 4) / 5), int(trainLen / 5)]\n",
    ")\n",
    "\n",
    "trainData1Loader = torch.utils.data.DataLoader(\n",
    "    dataset=trainData1, shuffle=False, batch_size=4\n",
    ")\n",
    "valDataLoader = torch.utils.data.DataLoader(\n",
    "    dataset=valData, shuffle=False, batch_size=4\n",
    ")\n",
    "\n",
    "######## DIVIDE BY 255 ############### TO NORMALIZE THE DATA. forget about transforms.Normalize\n",
    "# print(\"Length of train data = \",trainLen)\n",
    "# img_means = torch.stack([t.mean(1).mean(1) for t,c in trainData])\n",
    "# print(img_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T14:35:27.435719Z",
     "iopub.status.busy": "2024-01-13T14:35:27.434728Z",
     "iopub.status.idle": "2024-01-13T14:35:27.462466Z",
     "shell.execute_reply": "2024-01-13T14:35:27.460456Z",
     "shell.execute_reply.started": "2024-01-13T14:35:27.435719Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "950"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T14:35:29.295080Z",
     "iopub.status.busy": "2024-01-13T14:35:29.293082Z",
     "iopub.status.idle": "2024-01-13T14:35:35.326249Z",
     "shell.execute_reply": "2024-01-13T14:35:35.325247Z",
     "shell.execute_reply.started": "2024-01-13T14:35:29.295080Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading test dataset\n",
    "testData = torch.stack(\n",
    "    load_test_data(PATH + \"test\", transform=transform[\"test\"])\n",
    ")  # For converting list to tensor\n",
    "# testData = transform(testData)\n",
    "testDataLoader = torch.utils.data.DataLoader(dataset=testData, batch_size=4)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T14:35:55.698936Z",
     "iopub.status.busy": "2024-01-13T14:35:55.696945Z",
     "iopub.status.idle": "2024-01-13T14:35:55.714712Z",
     "shell.execute_reply": "2024-01-13T14:35:55.711691Z",
     "shell.execute_reply.started": "2024-01-13T14:35:55.698936Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATASET === \n",
      "No. of examples =  3800\n",
      "VAL SET ==== \n",
      "No. of examples = 950\n",
      "\n",
      "TEST DATASET ===\n",
      "No. of exmaples =  794\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAIN DATASET === \")\n",
    "print(\"No. of examples = \", len(trainData1Loader.dataset))\n",
    "print(\"VAL SET ==== \")\n",
    "print(\"No. of examples =\", len(valDataLoader.dataset))\n",
    "print(\"\\nTEST DATASET ===\")\n",
    "print(\"No. of exmaples = \", testDataLoader.dataset.size()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T14:35:57.084002Z",
     "iopub.status.busy": "2024-01-13T14:35:57.080999Z",
     "iopub.status.idle": "2024-01-13T14:35:57.146449Z",
     "shell.execute_reply": "2024-01-13T14:35:57.144445Z",
     "shell.execute_reply.started": "2024-01-13T14:35:57.083012Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_SingleProcessDataLoaderIter' object has no attribute 'next'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 20\u001b[0m\n\u001b[0;32m     16\u001b[0m     plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain images batch = 4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(trainData1Loader)\n\u001b[1;32m---> 20\u001b[0m image, label \u001b[38;5;241m=\u001b[39m \u001b[43miterator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m()\n\u001b[0;32m     22\u001b[0m imageShow(torchvision\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mmake_grid(image))\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# print('Ground Truth = \\n',' '.join('%10s' % trainData1Loader.dataset.classes[x] for x in label.numpy()))\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: '_SingleProcessDataLoaderIter' object has no attribute 'next'"
     ]
    }
   ],
   "source": [
    "# Visualizing Train dataset\n",
    "\"\"\"\n",
    "In trainDataLoader Dimensions are given as\n",
    "dim. index              0    1    2\n",
    "Actual Dims.           [3   128  128]\n",
    "\n",
    "These dimension are not suitable for plt.imshow() it needs dimensions in the format HxWxC but we have CxHxW\n",
    "So to change this we need our this dim. sequence = 0,1,2 in this format i.e. new dim. sequence 1,2,0 i.e. HxWxC\n",
    "So thats what np.transpose(img,(1,2,0)) is doing its changing the dims to suitable format.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def imageShow(img):\n",
    "    img = 255 * np.transpose(img.numpy(), (1, 2, 0))\n",
    "    plt.imshow(img)\n",
    "    plt.xlabel(\"Train images batch = 4\")\n",
    "\n",
    "\n",
    "iterator = iter(trainData1Loader)\n",
    "image, label = iterator.next()\n",
    "\n",
    "imageShow(torchvision.utils.make_grid(image))\n",
    "# print('Ground Truth = \\n',' '.join('%10s' % trainData1Loader.dataset.classes[x] for x in label.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T14:36:06.476997Z",
     "iopub.status.busy": "2024-01-13T14:36:06.476003Z",
     "iopub.status.idle": "2024-01-13T14:36:06.508299Z",
     "shell.execute_reply": "2024-01-13T14:36:06.505292Z",
     "shell.execute_reply.started": "2024-01-13T14:36:06.476997Z"
    }
   },
   "outputs": [],
   "source": [
    "# Forward => loss => backward => update_weights\n",
    "def train_model(\n",
    "    model, criterion, optimizer, scheduler, dataloader, dictionary, num_epochs=4\n",
    "):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    totalLoss = []\n",
    "    prediction = []\n",
    "    temp = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch {}/{}\\n\".format(epoch, num_epochs - 1), flush=True)\n",
    "        scheduler.step()  # to step or to update weights\n",
    "        model.train()\n",
    "\n",
    "        for batch_id, (image, label) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            outputs = model(image)\n",
    "            _, predictionIndex = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, label)\n",
    "            prediction.append(predictionIndex)\n",
    "\n",
    "            # printing loss =\n",
    "            print(\n",
    "                \"batch = \" + str(batch_id) + \" Loss = {0:.5f}\".format(loss.item()),\n",
    "                end=\"\\r\",\n",
    "                flush=True,\n",
    "            )\n",
    "            correct += (predictionIndex == label).sum().item()\n",
    "            total += label.size(0)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            del image, label  # important\n",
    "\n",
    "        totalLoss.append(loss)\n",
    "        #         prediction.append(temp)\n",
    "        torch.cuda.empty_cache()  # important\n",
    "\n",
    "    dictionary[\"totalLoss\"] = totalLoss\n",
    "    dictionary[\"correct\"] = correct\n",
    "    dictionary[\"totalSize\"] = total\n",
    "    dictionary[\"prediction\"] = prediction\n",
    "\n",
    "    # ALWAYS return the model object\n",
    "    return model, dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T14:36:13.525030Z",
     "iopub.status.busy": "2024-01-13T14:36:13.524040Z",
     "iopub.status.idle": "2024-01-13T14:36:13.542019Z",
     "shell.execute_reply": "2024-01-13T14:36:13.537010Z",
     "shell.execute_reply.started": "2024-01-13T14:36:13.525030Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #Unfreezing layers\n",
    "\n",
    "# model_ft = models.vgg16(pretrained=True)\n",
    "\n",
    "# model_ft.classifier[6].out_features = 12\n",
    "\n",
    "\n",
    "# # num_ftr = model_ft.fc.in_features\n",
    "\n",
    "# # model_ft.fc = nn.Linear(num_ftr,12)\n",
    "# # # model_ft.fc1 = nn.LogSoftmax()\n",
    "# # # # print(model_ft.parameters)\n",
    "# model_ft = model_ft.to(device)\n",
    "# # print(model_ft)\n",
    "# criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "# optimizer_ft = torch.optim.SGD(params=model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T14:36:14.631527Z",
     "iopub.status.busy": "2024-01-13T14:36:14.630530Z",
     "iopub.status.idle": "2024-01-13T14:36:14.640595Z",
     "shell.execute_reply": "2024-01-13T14:36:14.638588Z",
     "shell.execute_reply.started": "2024-01-13T14:36:14.631527Z"
    }
   },
   "outputs": [],
   "source": [
    "# dictModel = {}\n",
    "# model_ft,dictModel = train_model(model_ft,criterion,optimizer_ft,exp_lr_scheduler,dictionary=dictModel,num_epochs=12,dataloader=trainData1Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T14:38:13.184103Z",
     "iopub.status.busy": "2024-01-13T14:38:13.182107Z",
     "iopub.status.idle": "2024-01-13T14:38:15.681841Z",
     "shell.execute_reply": "2024-01-13T14:38:15.680838Z",
     "shell.execute_reply.started": "2024-01-13T14:38:13.184103Z"
    }
   },
   "outputs": [],
   "source": [
    "# FREEZE the LAYERS:\n",
    "\n",
    "model_conv = models.vgg16(weights=\"VGG16_Weights.DEFAULT\")\n",
    "# cnt = 0\n",
    "# for params in model_conv.parameters():\n",
    "#     if(cnt<=9):\n",
    "#         params.requires_grad = False\n",
    "#     cnt+=1\n",
    "model_conv.features.requires_grad = False\n",
    "model_conv.classifier.requires_grad = True\n",
    "# model_conv.classifier[6].requires_grad = True\n",
    "\n",
    "model_conv.classifier[6].out_features = 12\n",
    "# print(model_ft)\n",
    "\n",
    "# num_ftr = model_conv.fc.in_features\n",
    "\n",
    "# model_conv.fc = nn.Linear(num_ftr,12)\n",
    "# # model_ft.fc1 = nn.LogSoftmax()\n",
    "# # # print(model_ft.parameters)\n",
    "\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "optimizer_ft_conv = torch.optim.SGD(\n",
    "    params=model_conv.classifier.parameters(), lr=0.001, momentum=0.9\n",
    ")\n",
    "\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer_ft_conv, step_size=7, gamma=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T14:36:20.303695Z",
     "iopub.status.busy": "2024-01-13T14:36:20.301696Z",
     "iopub.status.idle": "2024-01-13T14:36:50.590841Z",
     "shell.execute_reply": "2024-01-13T14:36:50.587836Z",
     "shell.execute_reply.started": "2024-01-13T14:36:20.303695Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Milan\\Documents\\Projekti\\Virtualna Okruzenja\\ml-okruzenje\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch = 3 Loss = 7.44799\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m dictModel \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m----> 2\u001b[0m model_ft, dictModel \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_conv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer_ft_conv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_lr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdictionary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdictModel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainData1Loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 22\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, scheduler, dataloader, dictionary, num_epochs)\u001b[0m\n\u001b[0;32m     19\u001b[0m image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     20\u001b[0m label \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 22\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m _, predictionIndex \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, label)\n",
      "File \u001b[1;32m~\\Documents\\Projekti\\Virtualna Okruzenja\\ml-okruzenje\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\Projekti\\Virtualna Okruzenja\\ml-okruzenje\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\Projekti\\Virtualna Okruzenja\\ml-okruzenje\\Lib\\site-packages\\torchvision\\models\\vgg.py:66\u001b[0m, in \u001b[0;36mVGG.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m---> 66\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[0;32m     68\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\Projekti\\Virtualna Okruzenja\\ml-okruzenje\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\Projekti\\Virtualna Okruzenja\\ml-okruzenje\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\Projekti\\Virtualna Okruzenja\\ml-okruzenje\\Lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\Documents\\Projekti\\Virtualna Okruzenja\\ml-okruzenje\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\Projekti\\Virtualna Okruzenja\\ml-okruzenje\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\Projekti\\Virtualna Okruzenja\\ml-okruzenje\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\Projekti\\Virtualna Okruzenja\\ml-okruzenje\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dictModel = {}\n",
    "model_ft, dictModel = train_model(\n",
    "    model_conv,\n",
    "    criterion,\n",
    "    optimizer_ft_conv,\n",
    "    exp_lr_scheduler,\n",
    "    dictionary=dictModel,\n",
    "    num_epochs=2,\n",
    "    dataloader=trainData1Loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T14:36:50.591839Z",
     "iopub.status.idle": "2024-01-13T14:36:50.593841Z",
     "shell.execute_reply": "2024-01-13T14:36:50.592845Z",
     "shell.execute_reply.started": "2024-01-13T14:36:50.592845Z"
    }
   },
   "outputs": [],
   "source": [
    "dictModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T14:36:50.596839Z",
     "iopub.status.idle": "2024-01-13T14:36:50.597839Z",
     "shell.execute_reply": "2024-01-13T14:36:50.597839Z",
     "shell.execute_reply.started": "2024-01-13T14:36:50.597839Z"
    }
   },
   "outputs": [],
   "source": [
    "# loss vs iteration graph:\n",
    "plt.plot(dictModel[\"totalLoss\"])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T12:38:01.084400Z",
     "iopub.status.busy": "2024-01-13T12:38:01.082409Z",
     "iopub.status.idle": "2024-01-13T12:38:01.144478Z",
     "shell.execute_reply": "2024-01-13T12:38:01.136710Z",
     "shell.execute_reply.started": "2024-01-13T12:38:01.084400Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'correct'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Accuracy = \u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m100\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[43mdictModel\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcorrect\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m/\u001b[39mdictModel[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotalSize\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "\u001b[1;31mKeyError\u001b[0m: 'correct'"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy = \", 100 * (dictModel[\"correct\"] / dictModel[\"totalSize\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T12:37:45.676908Z",
     "iopub.status.idle": "2024-01-13T12:37:45.680889Z",
     "shell.execute_reply": "2024-01-13T12:37:45.680889Z",
     "shell.execute_reply.started": "2024-01-13T12:37:45.680889Z"
    }
   },
   "outputs": [],
   "source": [
    "# Validation set:\n",
    "dict_model_val = {}\n",
    "model_ft_val, dict_model_val = train_model(\n",
    "    model_conv,\n",
    "    criterion,\n",
    "    optimizer_ft,\n",
    "    exp_lr_scheduler,\n",
    "    dictionary=dict_model_val,\n",
    "    num_epochs=5,\n",
    "    dataloader=valDataLoader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T12:37:45.685304Z",
     "iopub.status.idle": "2024-01-13T12:37:45.687310Z",
     "shell.execute_reply": "2024-01-13T12:37:45.686309Z",
     "shell.execute_reply.started": "2024-01-13T12:37:45.686309Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Val Accuracy = \", 100 * (dict_model_val[\"correct\"] / dict_model_val[\"totalSize\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T12:37:45.688053Z",
     "iopub.status.idle": "2024-01-13T12:37:45.696883Z",
     "shell.execute_reply": "2024-01-13T12:37:45.696883Z",
     "shell.execute_reply.started": "2024-01-13T12:37:45.696883Z"
    }
   },
   "outputs": [],
   "source": [
    "# Validation set\n",
    "plt.plot(dict_model_val[\"totalLoss\"])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T12:37:45.700882Z",
     "iopub.status.idle": "2024-01-13T12:37:45.701879Z",
     "shell.execute_reply": "2024-01-13T12:37:45.701879Z",
     "shell.execute_reply.started": "2024-01-13T12:37:45.700882Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_conv = model_conv.to(device)\n",
    "model_conv = model_conv.eval()\n",
    "\n",
    "result = []\n",
    "\n",
    "# for batch_id,image in enumerate(testDataLoader):\n",
    "#     img = image.to(device)\n",
    "# #     print(img.size())\n",
    "#     ip = torch.autograd.Variable(img)\n",
    "#     testOutput = model_conv(ip)\n",
    "#     _, testPredictionIndex = torch.max(testOutput,1)\n",
    "#     result.append(testPredictionIndex)\n",
    "\n",
    "temp = torch.unsqueeze(testDataLoader.dataset[0], 0)\n",
    "# x = model_conv(temp.cuda())\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T12:37:45.704878Z",
     "iopub.status.idle": "2024-01-13T12:37:45.705877Z",
     "shell.execute_reply": "2024-01-13T12:37:45.705877Z",
     "shell.execute_reply.started": "2024-01-13T12:37:45.705877Z"
    }
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T12:37:45.708874Z",
     "iopub.status.idle": "2024-01-13T12:37:45.710385Z",
     "shell.execute_reply": "2024-01-13T12:37:45.709878Z",
     "shell.execute_reply.started": "2024-01-13T12:37:45.709878Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = []\n",
    "for x in result:\n",
    "    for y in x.cpu().numpy():\n",
    "        temp.append(y)\n",
    "len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T12:37:45.714813Z",
     "iopub.status.idle": "2024-01-13T12:37:45.716810Z",
     "shell.execute_reply": "2024-01-13T12:37:45.716810Z",
     "shell.execute_reply.started": "2024-01-13T12:37:45.716810Z"
    }
   },
   "outputs": [],
   "source": [
    "dfDict = {\n",
    "    \"file\": os.listdir(PATH + \"test\"),\n",
    "    \"species\": [trainData.classes[m] for m in temp],\n",
    "}\n",
    "df = pd.DataFrame(dfDict)\n",
    "df.to_csv(path_or_buf=\"submission.csv\", index=False)\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
